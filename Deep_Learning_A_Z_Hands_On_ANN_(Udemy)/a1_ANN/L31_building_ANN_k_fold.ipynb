{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Part-1:-Preprocessing\" data-toc-modified-id=\"Part-1:-Preprocessing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Part 1: Preprocessing</a></span></li><li><span><a href=\"#Part-2:-Make-the-ANN\" data-toc-modified-id=\"Part-2:-Make-the-ANN-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Part 2: Make the ANN</a></span></li><li><span><a href=\"#Part-3:-Prediction\" data-toc-modified-id=\"Part-3:-Prediction-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Part 3: Prediction</a></span></li><li><span><a href=\"#Part-4:-Evaluating,-Improving-and-Tuning-the-ANN\" data-toc-modified-id=\"Part-4:-Evaluating,-Improving-and-Tuning-the-ANN-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Part 4: Evaluating, Improving and Tuning the ANN</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dropout\" data-toc-modified-id=\"Dropout-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Dropout</a></span></li><li><span><a href=\"#Parameter-tuning-using-Grid-Search\" data-toc-modified-id=\"Parameter-tuning-using-Grid-Search-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Parameter tuning using Grid Search</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:30:57.912693Z",
     "start_time": "2019-01-18T01:30:57.495908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 14)\n",
      "[619 'France' 'Female' 42 2 0.0 1 1 1 101348.88]\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "df = pd.read_csv('../data/csv/Churn_Modelling.csv')\n",
    "X = df.iloc[:,3:-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "print(df.shape)\n",
    "print(X[0])\n",
    "print(y[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-29T02:57:14.552126Z",
     "start_time": "2018-12-29T02:57:14.235258Z"
    }
   },
   "source": [
    "# Part 1: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:30:58.324129Z",
     "start_time": "2019-01-18T01:30:57.915772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 11)\n",
      "[0.0000000e+00 0.0000000e+00 6.1900000e+02 0.0000000e+00 4.2000000e+01\n",
      " 2.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0134888e+05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/poudel/miniconda3/envs/tf/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/poudel/miniconda3/envs/tf/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>528</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>102016.72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80181.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>497</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76390.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>476</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26260.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>549</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190857.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>635</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65951.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>616</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>143129.41</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64327.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>653</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>132602.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5097.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>549</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14406.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>587</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158684.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>726</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54724.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0           619    France  Female   42       2       0.00              1   \n",
       "1           608     Spain  Female   41       1   83807.86              1   \n",
       "2           502    France  Female   42       8  159660.80              3   \n",
       "3           699    France  Female   39       1       0.00              2   \n",
       "4           850     Spain  Female   43       2  125510.82              1   \n",
       "5           645     Spain    Male   44       8  113755.78              2   \n",
       "6           822    France    Male   50       7       0.00              2   \n",
       "7           376   Germany  Female   29       4  115046.74              4   \n",
       "8           501    France    Male   44       4  142051.07              2   \n",
       "9           684    France    Male   27       2  134603.88              1   \n",
       "10          528    France    Male   31       6  102016.72              2   \n",
       "11          497     Spain    Male   24       3       0.00              2   \n",
       "12          476    France  Female   34      10       0.00              2   \n",
       "13          549    France  Female   25       5       0.00              2   \n",
       "14          635     Spain  Female   35       7       0.00              2   \n",
       "15          616   Germany    Male   45       3  143129.41              2   \n",
       "16          653   Germany    Male   58       1  132602.88              1   \n",
       "17          549     Spain  Female   24       9       0.00              2   \n",
       "18          587     Spain    Male   45       6       0.00              1   \n",
       "19          726    France  Female   24       6       0.00              2   \n",
       "\n",
       "    HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0           1               1        101348.88  \n",
       "1           0               1        112542.58  \n",
       "2           1               0        113931.57  \n",
       "3           0               0         93826.63  \n",
       "4           1               1         79084.10  \n",
       "5           1               0        149756.71  \n",
       "6           1               1         10062.80  \n",
       "7           1               0        119346.88  \n",
       "8           0               1         74940.50  \n",
       "9           1               1         71725.73  \n",
       "10          0               0         80181.12  \n",
       "11          1               0         76390.01  \n",
       "12          1               0         26260.98  \n",
       "13          0               0        190857.79  \n",
       "14          1               1         65951.65  \n",
       "15          0               1         64327.26  \n",
       "16          1               0          5097.67  \n",
       "17          1               1         14406.41  \n",
       "18          0               0        158684.81  \n",
       "19          1               1         54724.03  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149756.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10062.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119346.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74940.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71725.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>102016.72</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80181.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76390.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26260.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190857.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65951.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>143129.41</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64327.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>653.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>132602.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5097.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14406.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158684.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>726.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54724.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1      2    3     4     5          6    7    8    9          10\n",
       "0   0.0  0.0  619.0  0.0  42.0   2.0       0.00  1.0  1.0  1.0  101348.88\n",
       "1   0.0  1.0  608.0  0.0  41.0   1.0   83807.86  1.0  0.0  1.0  112542.58\n",
       "2   0.0  0.0  502.0  0.0  42.0   8.0  159660.80  3.0  1.0  0.0  113931.57\n",
       "3   0.0  0.0  699.0  0.0  39.0   1.0       0.00  2.0  0.0  0.0   93826.63\n",
       "4   0.0  1.0  850.0  0.0  43.0   2.0  125510.82  1.0  1.0  1.0   79084.10\n",
       "5   0.0  1.0  645.0  1.0  44.0   8.0  113755.78  2.0  1.0  0.0  149756.71\n",
       "6   0.0  0.0  822.0  1.0  50.0   7.0       0.00  2.0  1.0  1.0   10062.80\n",
       "7   1.0  0.0  376.0  0.0  29.0   4.0  115046.74  4.0  1.0  0.0  119346.88\n",
       "8   0.0  0.0  501.0  1.0  44.0   4.0  142051.07  2.0  0.0  1.0   74940.50\n",
       "9   0.0  0.0  684.0  1.0  27.0   2.0  134603.88  1.0  1.0  1.0   71725.73\n",
       "10  0.0  0.0  528.0  1.0  31.0   6.0  102016.72  2.0  0.0  0.0   80181.12\n",
       "11  0.0  1.0  497.0  1.0  24.0   3.0       0.00  2.0  1.0  0.0   76390.01\n",
       "12  0.0  0.0  476.0  0.0  34.0  10.0       0.00  2.0  1.0  0.0   26260.98\n",
       "13  0.0  0.0  549.0  0.0  25.0   5.0       0.00  2.0  0.0  0.0  190857.79\n",
       "14  0.0  1.0  635.0  0.0  35.0   7.0       0.00  2.0  1.0  1.0   65951.65\n",
       "15  1.0  0.0  616.0  1.0  45.0   3.0  143129.41  2.0  0.0  1.0   64327.26\n",
       "16  1.0  0.0  653.0  1.0  58.0   1.0  132602.88  1.0  1.0  0.0    5097.67\n",
       "17  0.0  1.0  549.0  0.0  24.0   9.0       0.00  2.0  1.0  1.0   14406.41\n",
       "18  0.0  1.0  587.0  1.0  45.0   6.0       0.00  1.0  0.0  0.0  158684.81\n",
       "19  0.0  0.0  726.0  0.0  24.0   6.0       0.00  2.0  1.0  1.0   54724.03"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# encode geography country names\n",
    "le_geo = LabelEncoder()\n",
    "X[:, 1] = le_geo.fit_transform(X[:, 1])\n",
    "\n",
    "# encode gender male female\n",
    "le_gen = LabelEncoder()\n",
    "X[:, 2] = le_gen.fit_transform(X[:, 2])\n",
    "\n",
    "ohe = OneHotEncoder(categorical_features=[1])\n",
    "X = ohe.fit_transform(X).toarray()\n",
    "X = X[:, 1:] # do not take first dummy variable\n",
    "\n",
    "print(X.shape)\n",
    "print(X[0])\n",
    "df2 = pd.DataFrame(X)\n",
    "\n",
    "display(df.iloc[:,3:-1].head(20), df2.head(20))\n",
    "# we can see france is 0,0  and female is 0 categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:30:58.348105Z",
     "start_time": "2019-01-18T01:30:58.326566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:30:58.358038Z",
     "start_time": "2019-01-18T01:30:58.350111Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Make the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:32:13.444112Z",
     "start_time": "2019-01-18T01:30:58.359996Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 127us/step - loss: 0.4815 - acc: 0.7957\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 0.4256 - acc: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4202 - acc: 0.8062: 0s - loss: 0.4184 - acc: 0.80\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4174 - acc: 0.8257: 0s - loss: 0.4198 - acc: \n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4155 - acc: 0.8290\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4136 - acc: 0.8312\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4121 - acc: 0.8302\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4107 - acc: 0.8329\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4103 - acc: 0.8329\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 0.4093 - acc: 0.8334\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 0.4082 - acc: 0.8344\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 0.4080 - acc: 0.8326\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4070 - acc: 0.8335\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4066 - acc: 0.8341\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4060 - acc: 0.8334\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 0.4054 - acc: 0.8339: 0s - loss: 0.3977 - acc\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.4049 - acc: 0.8325\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 0.4047 - acc: 0.8346: 0s - loss: 0.4053 - acc: 0.83\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 0.4043 - acc: 0.8339\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4037 - acc: 0.8342\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4034 - acc: 0.8352\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4038 - acc: 0.8355\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 96us/step - loss: 0.4028 - acc: 0.8350\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 0.4034 - acc: 0.8324\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 0.4032 - acc: 0.8346\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 0.4029 - acc: 0.8340: 0s - loss: 0.4060 - acc: 0.\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 0.4027 - acc: 0.8334\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4028 - acc: 0.8364\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4021 - acc: 0.8331\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4025 - acc: 0.8337\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4025 - acc: 0.8345\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4019 - acc: 0.8351\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4022 - acc: 0.8354: 0s - loss: 0.4063 - acc\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 0.4020 - acc: 0.8354: 0s - loss: 0.4018 - ac\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4012 - acc: 0.8341\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4016 - acc: 0.8341\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4017 - acc: 0.8356\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4018 - acc: 0.8342\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4014 - acc: 0.8357: 0s - loss: 0.3926 - acc:\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4014 - acc: 0.8346\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4010 - acc: 0.8346\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4015 - acc: 0.8350\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4011 - acc: 0.8354\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4013 - acc: 0.8347: 0s - loss: 0.4055 - acc: 0.8\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4012 - acc: 0.8339\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4011 - acc: 0.8346\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4012 - acc: 0.8369\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4009 - acc: 0.8335: 0s - loss: 0.4067 - acc: 0\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4013 - acc: 0.8347\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4012 - acc: 0.8340\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4007 - acc: 0.8340\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4010 - acc: 0.8354\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4011 - acc: 0.8346\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4008 - acc: 0.8350\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4005 - acc: 0.8350\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4008 - acc: 0.8360\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 0.4010 - acc: 0.8352\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 0.4010 - acc: 0.8362\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 0.4005 - acc: 0.8357\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4005 - acc: 0.8355\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4010 - acc: 0.8356: 0s - loss: 0.4013 - acc: 0.835\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4004 - acc: 0.8334\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4006 - acc: 0.8345\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 0.4005 - acc: 0.8344\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4004 - acc: 0.8350\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s 99us/step - loss: 0.4009 - acc: 0.8346\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 0.4005 - acc: 0.8357\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4012 - acc: 0.8346: 0s - loss: 0.4069 - a\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4005 - acc: 0.8346: 0s - loss: 0.3953 - ac\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4007 - acc: 0.8347\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 0.4005 - acc: 0.8361: 0s - loss: 0.4091 - acc\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 0.4000 - acc: 0.8349\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 0.4005 - acc: 0.8346\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 0.4003 - acc: 0.8354\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 0.4005 - acc: 0.8356\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4004 - acc: 0.8341\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4002 - acc: 0.8339\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4004 - acc: 0.8355: 0s - loss: 0.4021 - acc: 0.833\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.3998 - acc: 0.8345\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4002 - acc: 0.8339\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4004 - acc: 0.8352\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4001 - acc: 0.8362\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4004 - acc: 0.8347\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4003 - acc: 0.8355: 0s - loss: 0.4050 - a\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4002 - acc: 0.8350\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4003 - acc: 0.8346\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4001 - acc: 0.8319\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4000 - acc: 0.8354\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4004 - acc: 0.8339\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4004 - acc: 0.8351\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4002 - acc: 0.8356\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4003 - acc: 0.8365\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4000 - acc: 0.8347\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 0.4005 - acc: 0.8352\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.3999 - acc: 0.8360\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4005 - acc: 0.8340\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.3992 - acc: 0.8335\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4001 - acc: 0.8356\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.4002 - acc: 0.8354\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.3999 - acc: 0.8342\n",
      "0.842\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Build classifier\n",
    "clf = Sequential()\n",
    "clf.add(Dense(units=6, kernel_initializer='uniform', activation='relu',input_dim=11))\n",
    "clf.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
    "clf.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "clf.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# fitting\n",
    "clf.fit(X_train,y_train, batch_size=10, epochs=100)\n",
    "\n",
    "# prediction\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# confusion matrix and accuracy\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = (cm[0,0] + cm[1,1]) / np.sum(cm.flatten())\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:32:13.463760Z",
     "start_time": "2019-01-18T01:32:13.445723Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:32:13.475381Z",
     "start_time": "2019-01-18T01:32:13.465212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1543,   52],\n",
       "       [ 264,  141]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:32:13.482646Z",
     "start_time": "2019-01-18T01:32:13.477467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.842"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = (cm[0,0] + cm[1,1]) / np.sum(cm.flatten())\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Evaluating, Improving and Tuning the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:38:04.010611Z",
     "start_time": "2019-01-18T01:32:13.484971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8441249937564134 0.01204224272181121\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def build_classifier():\n",
    "    clf = Sequential()\n",
    "    clf.add(Dense(units=6, kernel_initializer='uniform', activation='relu',input_dim=11))\n",
    "    clf.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
    "    clf.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    clf.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return clf\n",
    "\n",
    "clf = KerasClassifier(build_fn=build_classifier, batch_size=10, epochs=100)\n",
    "acc = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=10, n_jobs=-1)\n",
    "\n",
    "mean = acc.mean()\n",
    "std= acc.std()\n",
    "\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-29T18:53:58.954231Z",
     "start_time": "2018-12-29T18:53:58.950680Z"
    }
   },
   "source": [
    "##  Dropout\n",
    "dropout regularization to reduce overfitting if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:39:27.134276Z",
     "start_time": "2019-01-18T01:38:04.012977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 138us/step - loss: 0.4992 - acc: 0.7955 1s - loss: 0.5912 - a\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4382 - acc: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4355 - acc: 0.7960\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4326 - acc: 0.8110\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 0.4281 - acc: 0.8229 0s - loss: 0.4275 - acc: 0.823\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4300 - acc: 0.8212\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4252 - acc: 0.8275\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 0.4232 - acc: 0.8284 0s - loss: 0.4225 - acc: 0.\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 0.4210 - acc: 0.8247\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 0.4200 - acc: 0.8280 0s - loss: 0.4246 - acc: - ETA: 0s - loss: 0.4258 - acc: 0.\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 0.4205 - acc: 0.8251\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4221 - acc: 0.8280\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4207 - acc: 0.8280 0s - loss: 0.4233 - acc: 0.8\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4192 - acc: 0.8274 0s - loss: 0.457\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4182 - acc: 0.8282\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4167 - acc: 0.8282\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4159 - acc: 0.8279\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.4178 - acc: 0.8284\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4169 - acc: 0.8277 0s - loss: 0.4088 - \n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4170 - acc: 0.8294\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4194 - acc: 0.8274\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4168 - acc: 0.8284\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4164 - acc: 0.8321\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.4159 - acc: 0.8280\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 0.4111 - acc: 0.8329\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4126 - acc: 0.8301 0s - loss: 0.4051 - ac\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 99us/step - loss: 0.4123 - acc: 0.8315\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4172 - acc: 0.8291\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4145 - acc: 0.8290\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4123 - acc: 0.8305\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4137 - acc: 0.8305\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4140 - acc: 0.8311\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4115 - acc: 0.8309\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4119 - acc: 0.8334\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4109 - acc: 0.8321\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4146 - acc: 0.8291\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4123 - acc: 0.8324\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 0.4127 - acc: 0.8310 0s - loss: 0.4105 - \n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4096 - acc: 0.8325\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4119 - acc: 0.8295\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4121 - acc: 0.8321 0s - loss: 0.4134 - acc: 0.831\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 0.4134 - acc: 0.8310\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 0.4120 - acc: 0.8315 0s - loss: 0.4086 - acc: 0\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.4151 - acc: 0.8266\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4137 - acc: 0.8320\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.4092 - acc: 0.8314\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4109 - acc: 0.8345\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.4127 - acc: 0.8294 0s - loss: 0.4251 -\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4119 - acc: 0.8322\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 0.4156 - acc: 0.8297\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4119 - acc: 0.8319\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4117 - acc: 0.8326\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 0.4136 - acc: 0.8336\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4096 - acc: 0.8336\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4116 - acc: 0.8305\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4083 - acc: 0.8364 0s - loss: 0.3979 - acc: 0.8 - ETA: 0s - loss: 0.4061 - acc:\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 0.4166 - acc: 0.8306\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.4130 - acc: 0.8317\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 0.4136 - acc: 0.8324\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 0.4094 - acc: 0.8326\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 0.4136 - acc: 0.8309\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 0.4116 - acc: 0.8316\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4083 - acc: 0.8340\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4091 - acc: 0.8354 0s - loss: 0.4099 - acc: 0.\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 0.4119 - acc: 0.8322 0s - loss: 0.4089 - acc: 0.8\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.4145 - acc: 0.8292 0s - loss: 0.4038 -\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.4140 - acc: 0.8306\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.4123 - acc: 0.8341 0s - loss: 0.4168 - acc\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 119us/step - loss: 0.4129 - acc: 0.8314\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.4109 - acc: 0.8345\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 0.4134 - acc: 0.8314\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.4092 - acc: 0.8342 0s - loss: 0.4079 - acc: 0.83\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4129 - acc: 0.8312 0s - loss: 0.4140 - acc:\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 0.4115 - acc: 0.8321 0s - loss: 0.4122 - acc: 0.830 - ETA: 0s - loss: 0.4106 - acc\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4124 - acc: 0.8330\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4089 - acc: 0.8322\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4103 - acc: 0.8361\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 0.4078 - acc: 0.8372\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 0.4081 - acc: 0.8355\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.4133 - acc: 0.8324\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s 99us/step - loss: 0.4093 - acc: 0.8366: 0s - loss: 0.4105 - acc: \n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4088 - acc: 0.8362\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 125us/step - loss: 0.4113 - acc: 0.8352\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 0.4083 - acc: 0.8352\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4083 - acc: 0.8359\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.4106 - acc: 0.8357\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 0.4107 - acc: 0.8352\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 0.4096 - acc: 0.8346\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4105 - acc: 0.8375 0s - loss: 0.4208 - a\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 0.4102 - acc: 0.8350\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4086 - acc: 0.8347 0s - loss: 0.4097 - acc: 0.\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4058 - acc: 0.8366\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4090 - acc: 0.8365\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4086 - acc: 0.8346 0s - loss: 0.4093 - acc: 0\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 0.4110 - acc: 0.8356 0s - loss: 0.4048 - acc - ETA: 0s - loss: 0.4088 - acc: 0.837\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 0.4106 - acc: 0.8344\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 0.4103 - acc: 0.8364\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 0.4103 - acc: 0.8361\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 0.4109 - acc: 0.8349\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 0.4097 - acc: 0.8347\n",
      "0.845\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Build classifier\n",
    "clf = Sequential()\n",
    "\n",
    "clf.add(Dense(units=6, kernel_initializer='uniform', activation='relu',input_dim=11))\n",
    "clf.add(Dropout(0.1))\n",
    "\n",
    "clf.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
    "clf.add(Dropout(0.1))\n",
    "\n",
    "clf.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "clf.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# fitting\n",
    "clf.fit(X_train,y_train, batch_size=10, epochs=100)\n",
    "\n",
    "# prediction\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# confusion matrix and accuracy\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = (cm[0,0] + cm[1,1]) / np.sum(cm.flatten())\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:39:27.141881Z",
     "start_time": "2019-01-18T01:39:27.136471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ann_parameter_tuning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ann_parameter_tuning.py\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def build_classifier(optimizer):\n",
    "    clf = Sequential()\n",
    "    clf.add(Dense(units=6, kernel_initializer='uniform', activation='relu',input_dim=11))\n",
    "    clf.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
    "    clf.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    clf.compile(optimizer=optimizer, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return clf\n",
    "\n",
    "clf = KerasClassifier(build_fn=build_classifier)\n",
    "\n",
    "parameters = {'batch_size': [25, 32],\n",
    "             'epochs': [100,500],\n",
    "             'optimizer': ['adam', 'rmsprop']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf,\n",
    "                          param_grid = parameters,\n",
    "                          scoring='accuracy',\n",
    "                          cv = 10)\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_parameters = grid_search.best_params_\n",
    "best_acc = grid_search.best_score_\n",
    "\n",
    "print(best_parameters, best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (tensorflow)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
