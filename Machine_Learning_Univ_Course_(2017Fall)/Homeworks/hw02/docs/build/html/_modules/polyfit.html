<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>polyfit &#8212; Bhishan&#39;s 1 documentation</title>
    
    <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/sidebar.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
  </head>
  <body role="document">
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Bhishan&#39;s 1 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for polyfit</h1><div class="highlight"><pre>
<span></span><span class="ch">#!python</span>
<span class="c1"># -*- coding: utf-8 -*-#</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Polynomial Regresssion with Ridge Regression and Batch Gradient Descent.</span>

<span class="sd">@author: Bhishan Poudel, Physics PhD Student, Ohio University</span>

<span class="sd">@date: Oct 2, 2017</span>

<span class="sd">@email: bhishanpdl@gmail.com</span>

<span class="sd">:Outputs:</span>

<span class="sd">  - ../images/hw02qn4b.png</span>
<span class="sd">  - ../images/cost_epochs_good_lr.png</span>
<span class="sd">  - ../images/cost_epochs_bad_lr.png</span>
<span class="sd">  - ../images/cost_history_bgd_unreg.png</span>
<span class="sd">  - ../images/cost_history_bgd_reg.png</span>

<span class="sd">The cost function for the Ridge Regression is given by</span>

<span class="sd">.. math::</span>

<span class="sd">  J(w) = \\frac{1}{2N} \sum_{n=1}^N (h(x_n,w) - t_n)^2 + \</span>
<span class="sd">  \\frac{\lambda}{2} ||w||^2</span>

<span class="sd">In this case we use batch gradient descent method to model the training data.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="k">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="k">import</span> <span class="n">inv</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span><span class="n">pinv</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="k">import</span> <span class="nb">sum</span><span class="p">,</span> <span class="n">sqrt</span><span class="p">,</span> <span class="n">array</span><span class="p">,</span> <span class="n">log</span><span class="p">,</span> <span class="n">exp</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>  <span class="c1"># XXX : Never Recommended, just to ignore plot warnings.</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">formatter</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;float&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s2">&quot;</span><span class="si">{:,.4f}</span><span class="s2"> &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="p">)})</span>



<span class="c1"># Read data matrix X and labels t from text file.</span>
<div class="viewcode-block" id="read_data"><a class="viewcode-back" href="../polyfit.html#polyfit.read_data">[docs]</a><span class="k">def</span> <span class="nf">read_data</span><span class="p">(</span><span class="n">file_name</span><span class="p">):</span>
    <span class="o">*</span><span class="n">X</span><span class="p">,</span><span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span><span class="n">unpack</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">t</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">t</span></div>


<div class="viewcode-block" id="read_data_vander"><a class="viewcode-back" href="../polyfit.html#polyfit.read_data_vander">[docs]</a><span class="k">def</span> <span class="nf">read_data_vander</span><span class="p">(</span><span class="n">infile</span><span class="p">,</span> <span class="n">M</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Read the dataset and return vandermonde matrix Xvan for given degree M.</span>
<span class="sd">      &quot;&quot;&quot;</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="n">infile</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">double</span><span class="p">,</span><span class="n">unpack</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">Xvan</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vander</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">M</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">increasing</span> <span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># make column vector</span>

    <span class="c1"># # debug</span>
    <span class="c1"># print(&quot;Xvan.shape = {}&quot;.format(Xvan.shape)) # e.g 20, 10</span>
    <span class="c1"># print(&quot;t.shape = {}&quot;.format(t.shape)) # e.g. 20, 1</span>

    <span class="k">return</span> <span class="n">Xvan</span><span class="p">,</span> <span class="n">t</span></div>


<div class="viewcode-block" id="compute_cost_ridge"><a class="viewcode-back" href="../polyfit.html#polyfit.compute_cost_ridge">[docs]</a><span class="k">def</span> <span class="nf">compute_cost_ridge</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the cost function.</span>

<span class="sd">    .. math:: J = \\frac{1}{2N} \sum_{i=1}^{N} (h_n - t_n)^2 + \</span>
<span class="sd">    \\frac{\\lambda}{2} ||w||^2</span>

<span class="sd">    Args:</span>
<span class="sd">      X1(matrix): Design matrix with bias column.</span>
<span class="sd">      t(column vector): Target column vector.</span>
<span class="sd">      shrikage(float) : Shrinkage hyperparameter for Ridge L2 normalization.</span>
<span class="sd">      w(row vector) : Weight row vector.</span>

<span class="sd">    Return:</span>
<span class="sd">      J(float): Cost value.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Compute cost</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">X1</span> <span class="o">@</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span>
    <span class="n">J</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">h</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span><span class="mi">2</span> <span class="o">/</span> <span class="n">N</span> <span class="o">+</span> <span class="n">shrinkage</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">J</span></div>

<div class="viewcode-block" id="train_norm_eqn"><a class="viewcode-back" href="../polyfit.html#polyfit.train_norm_eqn">[docs]</a><span class="k">def</span> <span class="nf">train_norm_eqn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Train the data using normal equations.</span>

<span class="sd">    This model uses OLS method to train the data without the penalty term.</span>

<span class="sd">    .. math::</span>

<span class="sd">      J(w) = \\frac{1}{2N} \sum_{n=1}^N (h(x_n,w) - t_n)^2</span>

<span class="sd">    Args:</span>

<span class="sd">      X (array): Design matrix of size (m+1, n). I.e. There are</span>
<span class="sd">        m features and one bias column in the matrix X.</span>

<span class="sd">      t (column): target column vector</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span>  <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">t</span>   <span class="c1"># M = 5</span>

    <span class="c1"># make w row vector</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;w.shape normal eqn = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="c1"># 6,1</span>

    <span class="k">return</span> <span class="n">w</span></div>

<div class="viewcode-block" id="train_ridge_norm_eqn"><a class="viewcode-back" href="../polyfit.html#polyfit.train_ridge_norm_eqn">[docs]</a><span class="k">def</span> <span class="nf">train_ridge_norm_eqn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span> <span class="n">M</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Train data with ridge regression using normal equations.</span>

<span class="sd">    Args:</span>

<span class="sd">      X (array): Design matrix of size (m+1, n). I.e. There are</span>
<span class="sd">        m features and one bias column in the matrix X.</span>

<span class="sd">      t (column): Target column vector.</span>

<span class="sd">      shrinkage (float): The shrinkage hyperparameter  for the regularization.</span>

<span class="sd">      M (int): Degree of the polynomial to fit.</span>

<span class="sd">    Return:</span>

<span class="sd">      w(row): Weight vector in the shape of row.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># First get the identity matrix of size deg+1 by deg+1</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">I</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">M</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">I</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># don&#39;t regularize bias term.</span>


    <span class="c1"># weight for ridge regression from Normal Equations</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">inv</span><span class="p">(</span><span class="n">shrinkage</span> <span class="o">*</span> <span class="n">N</span> <span class="o">*</span> <span class="n">I</span> <span class="o">+</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span> <span class="p">)</span>   <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">t</span>

    <span class="k">return</span> <span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span></div>



<div class="viewcode-block" id="train_ridge_BGD"><a class="viewcode-back" href="../polyfit.html#polyfit.train_ridge_BGD">[docs]</a><span class="k">def</span> <span class="nf">train_ridge_BGD</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span> <span class="n">iters</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculate weight vector using Ridge Regression L2 norm using Batch Grad Desc.</span>

<span class="sd">    .. note::</span>

<span class="sd">       Note that X and t should be normalized before running batch grad descent.</span>

<span class="sd">    Args:</span>
<span class="sd">      X(matrix): Nomalized Design matrix with bias term.</span>

<span class="sd">      t(column vector): Normalized Target column vector (shape = 1, samples)</span>

<span class="sd">      shrikage(float): L2 regularization shrikage hyper parameter.</span>

<span class="sd">      iters(int): Number of iterations.</span>

<span class="sd">      learning_rate(float): Learning rate for gradient descent algorithm.</span>

<span class="sd">      Return:</span>

<span class="sd">        w(row): Weight vector in the shape of row.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">t</span> <span class="o">=</span><span class="n">t</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>

    <span class="c1"># debug</span>
    <span class="c1"># print(&quot;\n\n&quot;)</span>
    <span class="c1"># print(&quot;Inside ridge_BGD&quot;)</span>
    <span class="c1"># print(&quot;X.shape = {}&quot;.format(X.shape))</span>
    <span class="c1"># print(&quot;t.shape = {}&quot;.format(t.shape))</span>
    <span class="c1"># print(&quot;w.shape = {}&quot;.format(w.shape))</span>
    <span class="c1"># print(&quot;shrinkage = {}&quot;.format(shrinkage))</span>
    <span class="c1"># print(&quot;iters = {}&quot;.format(iters))</span>
    <span class="c1"># print(&quot;learning_rate = {}&quot;.format(learning_rate))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">iters</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span>

        <span class="c1"># MSE = np.square(h - t).mean()</span>
        <span class="c1"># print(&quot;MSE = {}&quot;.format(MSE))</span>

        <span class="n">grad_ols</span> <span class="o">=</span>  <span class="p">(</span><span class="n">h</span><span class="o">-</span><span class="n">t</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span> <span class="o">/</span> <span class="n">N</span>

        <span class="c1"># print(&quot;grad_ols.shape = {}&quot;.format(grad_ols.shape)) # 1,6 w is also 1,6</span>

        <span class="n">grad_ridge</span> <span class="o">=</span> <span class="p">(</span><span class="n">grad_ols</span> <span class="o">+</span> <span class="n">shrinkage</span>  <span class="o">*</span> <span class="n">w</span> <span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_ridge</span>

    <span class="c1"># make w row vector</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># shape = 1, feature + 1</span>
    <span class="k">return</span> <span class="n">w</span></div>

<div class="viewcode-block" id="train_ridge_BGD_threshold"><a class="viewcode-back" href="../polyfit.html#polyfit.train_ridge_BGD_threshold">[docs]</a><span class="k">def</span> <span class="nf">train_ridge_BGD_threshold</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">stepsize</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculate weight vector using Ridge Regression L2 norm using Batch Grad Desc.</span>

<span class="sd">    .. note::</span>

<span class="sd">       Note that X and t should be normalized before running batch grad descent.</span>

<span class="sd">    Args:</span>
<span class="sd">      X(matrix): Nomalized Design matrix with bias term.</span>

<span class="sd">      t(column vector): Normalized Target column vector (shape = 1, samples)</span>

<span class="sd">      shrikage(float): L2 regularization shrikage hyper parameter.</span>

<span class="sd">      ratio(float): Ratio of now to previous cost in grad descent calculation.</span>

<span class="sd">      learning_rate(float): Learning rate for gradient descent algorithm.</span>

<span class="sd">      stepsize(int): Step size of iterations to run. e.g 1 means 1,2,3,4...</span>
<span class="sd">      The answer heavily depends on stepsize in SGD.</span>

<span class="sd">      Return:</span>

<span class="sd">        w(row): Weight vector in the shape of row.</span>

<span class="sd">        final_iter(int): Final iteration when the model converges.</span>

<span class="sd">        J_hist(list): List of cost histories.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">t</span> <span class="o">=</span><span class="n">t</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># Initiliaze to zeros.</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>

    <span class="c1"># debug</span>
    <span class="c1"># print(&quot;\n\n&quot;)</span>
    <span class="c1"># print(&quot;Inside ridge_BGD&quot;)</span>
    <span class="c1"># print(&quot;x.shape = {}&quot;.format(X.shape))</span>
    <span class="c1"># print(&quot;t.shape = {}&quot;.format(t.shape))</span>
    <span class="c1"># print(&quot;w.shape = {}&quot;.format(w.shape))</span>
    <span class="c1"># print(&quot;shrinkage = {}&quot;.format(shrinkage))</span>
    <span class="c1"># print(&quot;iters = {}&quot;.format(iters))</span>
    <span class="c1"># print(&quot;learning_rate = {}&quot;.format(learning_rate))</span>
    <span class="n">J_prev</span> <span class="o">=</span> <span class="mf">1e9</span> <span class="c1"># initialize J to large initial value.</span>
    <span class="n">iters</span> <span class="o">=</span> <span class="mi">3000000000000</span> <span class="c1"># Take large number until you break</span>
    <span class="n">final_iter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">J_hist</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">iters</span><span class="p">,</span><span class="n">stepsize</span><span class="p">):</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">train_ridge_BGD</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
        <span class="n">J</span> <span class="o">=</span> <span class="n">compute_cost_ridge</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
        <span class="n">J_hist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">J</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;i = </span><span class="si">{:,}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
        <span class="c1"># print(&quot;J_prev-J  = {:.5f}    J_prev = {:.5f}     J = {:.5f}  &quot;.format(J_prev-J, J_prev, J ))</span>

        <span class="n">final_iter</span> <span class="o">=</span> <span class="n">i</span>
        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">J_prev</span> <span class="o">-</span> <span class="n">J</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">threshold</span><span class="p">:</span>
            <span class="k">break</span>

        <span class="c1"># Update J after the if statement.</span>
        <span class="n">J_prev</span> <span class="o">=</span> <span class="n">J</span>

    <span class="n">final_iter</span> <span class="o">=</span> <span class="n">final_iter</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">w</span><span class="p">,</span> <span class="n">final_iter</span><span class="p">,</span> <span class="n">J_hist</span></div>


<div class="viewcode-block" id="train_ridge_SGD"><a class="viewcode-back" href="../polyfit.html#polyfit.train_ridge_SGD">[docs]</a><span class="k">def</span> <span class="nf">train_ridge_SGD</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span> <span class="n">iters</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculate weight vector using Ridge Regression L2 norm using Batch Grad Desc.</span>

<span class="sd">    .. note::</span>

<span class="sd">       Note that X and t should be normalized before running batch grad descent.</span>

<span class="sd">    Args:</span>
<span class="sd">      X(matrix): Nomalized Design matrix with bias term.</span>

<span class="sd">      t(column vector): Normalized Target column vector (shape = 1, samples)</span>

<span class="sd">      shrikage(float): L2 regularization shrikage hyper parameter.</span>

<span class="sd">      iters(int): Number of iterations.</span>

<span class="sd">      learning_rate(float): Learning rate for gradient descent algorithm.</span>

<span class="sd">      Return:</span>

<span class="sd">        w(row): Weight vector in the shape of row.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">t</span> <span class="o">=</span><span class="n">t</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>

    <span class="c1"># debug</span>
    <span class="c1"># print(&quot;\n\n&quot;)</span>
    <span class="c1"># print(&quot;Inside ridge_BGD&quot;)</span>
    <span class="c1"># print(&quot;X.shape = {}&quot;.format(X.shape))</span>
    <span class="c1"># print(&quot;t.shape = {}&quot;.format(t.shape))</span>
    <span class="c1"># print(&quot;w.shape = {}&quot;.format(w.shape))</span>
    <span class="c1"># print(&quot;shrinkage = {}&quot;.format(shrinkage))</span>
    <span class="c1"># print(&quot;iters = {}&quot;.format(iters))</span>
    <span class="c1"># print(&quot;learning_rate = {}&quot;.format(learning_rate))</span>
    <span class="c1"># Initiliaze variables</span>
    <span class="n">Xj</span><span class="p">,</span> <span class="n">tj</span><span class="p">,</span> <span class="n">hj</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">iters</span><span class="p">):</span>

        <span class="c1"># shuffle the data for stochastic grad desc.</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">perm_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">perm_idx</span><span class="p">]</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="p">[</span><span class="n">perm_idx</span><span class="p">]</span>

        <span class="c1"># iterate over each row of data</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="c1"># row of data</span>
            <span class="n">Xj</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">,:]</span>
            <span class="n">hj</span> <span class="o">=</span> <span class="n">Xj</span> <span class="o">@</span> <span class="n">w</span><span class="o">.</span><span class="n">T</span>
            <span class="n">tj</span> <span class="o">=</span> <span class="n">t</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

            <span class="c1"># reshape</span>
            <span class="n">Xj</span> <span class="o">=</span> <span class="n">Xj</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">tj</span> <span class="o">=</span> <span class="n">tj</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">hj</span> <span class="o">=</span> <span class="n">hj</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># find gradient and update w row by row of design matrix.</span>
            <span class="n">grad_ols</span> <span class="o">=</span>  <span class="p">(</span><span class="n">hj</span><span class="o">-</span><span class="n">tj</span><span class="p">)</span> <span class="o">@</span> <span class="n">Xj</span><span class="o">.</span><span class="n">T</span> <span class="o">/</span> <span class="n">N</span>
            <span class="n">grad_ridge</span> <span class="o">=</span> <span class="p">(</span><span class="n">grad_ols</span> <span class="o">+</span> <span class="n">shrinkage</span>  <span class="o">*</span> <span class="n">w</span> <span class="p">)</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_ridge</span>

    <span class="c1"># debug</span>
    <span class="c1"># print(&quot;Xj.shape = {}&quot;.format(Xj.shape)) # 6,1</span>
    <span class="c1"># print(&quot;w.shape = {}&quot;.format(w.shape))   # 1,6</span>
    <span class="c1"># print(&quot;hj.shape = {}&quot;.format(hj.shape)) # 1,1</span>
    <span class="c1"># print(&quot;tj.shape = {}&quot;.format(tj.shape)) # 1,1</span>
    <span class="c1"># print(&quot;Xj = {}&quot;.format(Xj))</span>
    <span class="c1"># print(&quot;tj = {}&quot;.format(tj))</span>

    <span class="k">return</span> <span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span></div>

<div class="viewcode-block" id="plot_J_hist_threshold"><a class="viewcode-back" href="../polyfit.html#polyfit.plot_J_hist_threshold">[docs]</a><span class="k">def</span> <span class="nf">plot_J_hist_threshold</span><span class="p">(</span><span class="n">final_iter</span><span class="p">,</span> <span class="n">J_hist</span><span class="p">,</span><span class="n">ofile</span><span class="p">,</span><span class="n">title</span><span class="p">):</span>
    <span class="c1"># matplotlib customization</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">final_iter</span><span class="p">),</span> <span class="n">J_hist</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Cost history&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epochs/stepsize&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Cost  J(w)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">ofile</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></div>

<div class="viewcode-block" id="plot_cost_epoch"><a class="viewcode-back" href="../polyfit.html#polyfit.plot_cost_epoch">[docs]</a><span class="k">def</span> <span class="nf">plot_cost_epoch</span><span class="p">(</span><span class="n">Jvals_lst</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
    <span class="c1"># matplotlib customization</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>

    <span class="c1"># without lr 1 and 10</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">Jvals_lst</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;learning rate = 0.0001&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">Jvals_lst</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;learning rate = 0.001&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">Jvals_lst</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;learning rate = 0.01&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">Jvals_lst</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;learning rate = 0.1&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Cost  J(w)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Choosing hyperparameter learning_rate&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;../images/cost_epochs_good_lr.png&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="c1"># For learning rate 1 and 10 we get nans</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">Jvals_lst</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;learning rate = 1&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">Jvals_lst</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;learning rate = 10&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Cost  J(w)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Choosing hyperparameter learning_rate&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;../images/cost_epochs_bad_lr.png&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></div>


<div class="viewcode-block" id="plot_3data"><a class="viewcode-back" href="../polyfit.html#polyfit.plot_3data">[docs]</a><span class="k">def</span> <span class="nf">plot_3data</span><span class="p">():</span>
    <span class="n">data_files</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span><span class="s1">&#39;test&#39;</span><span class="p">,</span><span class="s1">&#39;devel&#39;</span><span class="p">]</span>
    <span class="n">styles</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bo&#39;</span><span class="p">,</span><span class="s1">&#39;g^&#39;</span><span class="p">,</span><span class="s1">&#39;r&gt;&#39;</span><span class="p">]</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span><span class="n">dpi</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data_file</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_files</span><span class="p">):</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="s1">&#39;../data/polyfit/</span><span class="si">{}</span><span class="s1">.txt&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data_file</span><span class="p">))</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;t&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">styles</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;../images/hw02qn4b.png&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></div>

<div class="viewcode-block" id="normalize_data"><a class="viewcode-back" href="../polyfit.html#polyfit.normalize_data">[docs]</a><span class="k">def</span> <span class="nf">normalize_data</span><span class="p">(</span><span class="n">fh_train</span><span class="p">,</span><span class="n">deg</span><span class="p">):</span>

    <span class="c1"># Get vandermonde matrix with bias column</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">read_data_vander</span><span class="p">(</span><span class="n">fh_train</span><span class="p">,</span> <span class="n">deg</span><span class="p">)</span>

    <span class="c1"># Zscore normalize all the columns of X except 1st bias column.</span>
    <span class="n">Xnot0</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
    <span class="n">Xnot0normalized</span> <span class="o">=</span> <span class="p">(</span><span class="n">Xnot0</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Xnot0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">Xnot0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># print(&quot;Xnot0[0] = {}&quot;.format(Xnot0[0]))</span>
    <span class="c1"># print(&quot;Xnot0normalized[0] = {}&quot;.format(Xnot0normalized[0]))</span>

    <span class="c1"># Append bias column back to zcale normalized matrix X.</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">Xnot0normalized</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># We do not feature normalize the target vector.</span>
    <span class="c1"># t = (t - np.mean(t, axis=0,keepdims=True)) / np.std(t, axis=0, keepdims=True)</span>
    <span class="c1"># print(&quot;X[0] = {}&quot;.format(X[0]))</span>
    <span class="c1"># print(&quot;t.shape = {}&quot;.format(t.shape))</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">t</span></div>

<div class="viewcode-block" id="choose_learning_rate"><a class="viewcode-back" href="../polyfit.html#polyfit.choose_learning_rate">[docs]</a><span class="k">def</span> <span class="nf">choose_learning_rate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">t</span><span class="p">):</span>
    <span class="n">shrinkage</span><span class="p">,</span> <span class="n">deg</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">510</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">learning_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="o">**</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">)]</span>
    <span class="n">Jvals_lst</span> <span class="o">=</span> <span class="p">[</span> <span class="p">[</span><span class="n">compute_cost_ridge</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span>  <span class="n">train_ridge_BGD</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">))</span>
             <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">epochs</span><span class="p">]</span> <span class="k">for</span> <span class="n">learning_rate</span> <span class="ow">in</span> <span class="n">learning_rates</span><span class="p">]</span>
    <span class="n">plot_cost_epoch</span><span class="p">(</span><span class="n">Jvals_lst</span><span class="p">,</span> <span class="n">epochs</span><span class="p">)</span></div>

<div class="viewcode-block" id="plot_cost_hist_unreg"><a class="viewcode-back" href="../polyfit.html#polyfit.plot_cost_hist_unreg">[docs]</a><span class="k">def</span> <span class="nf">plot_cost_hist_unreg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">t</span><span class="p">):</span>
    <span class="n">shrinkage</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">stepsize</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span>
    <span class="n">w_unreg_bgd</span><span class="p">,</span> <span class="n">final_iter</span><span class="p">,</span> <span class="n">J_hist</span> <span class="o">=</span> <span class="n">train_ridge_BGD_threshold</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">stepsize</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;w_unreg_bgd = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">w_unreg_bgd</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;final_iter = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">final_iter</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;len(J_hist) = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">J_hist</span><span class="p">)))</span>
    <span class="n">ofile</span> <span class="o">=</span> <span class="s1">&#39;../images/cost_history_bgd_unreg.png&#39;</span>
    <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;Cost history GD Unregularized&#39;</span>
    <span class="n">plot_J_hist_threshold</span><span class="p">(</span><span class="n">final_iter</span><span class="p">,</span> <span class="n">J_hist</span><span class="p">,</span> <span class="n">ofile</span><span class="p">,</span><span class="n">title</span><span class="p">)</span></div>

<div class="viewcode-block" id="compare_w_unreg"><a class="viewcode-back" href="../polyfit.html#polyfit.compare_w_unreg">[docs]</a><span class="k">def</span> <span class="nf">compare_w_unreg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">t</span><span class="p">):</span>

    <span class="c1"># run sgd fitting model</span>
    <span class="n">shrinkage</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">stepsize</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span>
    <span class="n">w_unreg_bgd</span><span class="p">,</span> <span class="n">final_iter</span><span class="p">,</span> <span class="n">J_hist</span> <span class="o">=</span> <span class="n">train_ridge_BGD_threshold</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">stepsize</span><span class="p">)</span>


    <span class="c1"># After fitting compare normal, gd and sgd methods.</span>
    <span class="n">shrinkage</span><span class="p">,</span> <span class="n">iters</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">deg</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">final_iter</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">5</span>
    <span class="n">w_norm_eqn</span> <span class="o">=</span> <span class="n">train_ridge_norm_eqn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span> <span class="n">deg</span><span class="p">)</span>
    <span class="n">w_unreg_bgd</span>      <span class="o">=</span> <span class="n">train_ridge_BGD</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span> <span class="n">iters</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
    <span class="n">w_unreg_sgd</span>      <span class="o">=</span> <span class="n">train_ridge_SGD</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span> <span class="n">iters</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;shrinkage = </span><span class="si">{:.2f}</span><span class="s2"> final_iter = </span><span class="si">{:d}</span><span class="s2"> learning_rate = </span><span class="si">{:.2f}</span><span class="s2"> deg = </span><span class="si">{:d}</span><span class="s2"> threshold = </span><span class="si">{:.2e}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">shrinkage</span><span class="p">,</span> <span class="n">final_iter</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">deg</span><span class="p">,</span> <span class="n">threshold</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;w_norm_eqn  = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">w_norm_eqn</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;w_unreg_bgd = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">w_unreg_bgd</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;w_unreg_sgd = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">w_unreg_sgd</span><span class="p">))</span></div>

<div class="viewcode-block" id="plot_cost_hist_reg"><a class="viewcode-back" href="../polyfit.html#polyfit.plot_cost_hist_reg">[docs]</a><span class="k">def</span> <span class="nf">plot_cost_hist_reg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">t</span><span class="p">):</span>
    <span class="n">shrinkage</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">stepsize</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1e-10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span>
    <span class="n">w_reg_bgd</span><span class="p">,</span> <span class="n">final_iter</span><span class="p">,</span> <span class="n">J_hist</span> <span class="o">=</span> <span class="n">train_ridge_BGD_threshold</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">stepsize</span><span class="p">)</span>
    <span class="c1"># print(&quot;w_unreg_bgd = {}&quot;.format(w_reg_bgd))</span>
    <span class="c1"># print(&quot;final_iter = {}&quot;.format(final_iter))</span>
    <span class="c1"># print(&quot;len(J_hist) = {}&quot;.format(len(J_hist)))</span>
    <span class="n">ofile</span> <span class="o">=</span> <span class="s1">&#39;../images/cost_history_bgd_reg.png&#39;</span>
    <span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;Cost history GD Regularized&#39;</span>
    <span class="n">plot_J_hist_threshold</span><span class="p">(</span><span class="n">final_iter</span><span class="p">,</span> <span class="n">J_hist</span><span class="p">,</span> <span class="n">ofile</span><span class="p">,</span><span class="n">title</span><span class="p">)</span></div>

<div class="viewcode-block" id="compare_w_reg"><a class="viewcode-back" href="../polyfit.html#polyfit.compare_w_reg">[docs]</a><span class="k">def</span> <span class="nf">compare_w_reg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">t</span><span class="p">):</span>
    <span class="n">shrinkage</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">stepsize</span><span class="p">,</span> <span class="n">deg</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1e-10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span>
    <span class="n">w_reg_bgd</span><span class="p">,</span> <span class="n">final_iter</span><span class="p">,</span> <span class="n">J_hist</span> <span class="o">=</span> <span class="n">train_ridge_BGD_threshold</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">stepsize</span><span class="p">)</span>
    <span class="n">w_norm_eqn</span> <span class="o">=</span> <span class="n">train_ridge_norm_eqn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span> <span class="n">deg</span><span class="p">)</span>
    <span class="n">w_reg_bgd</span>      <span class="o">=</span> <span class="n">train_ridge_BGD</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span> <span class="n">final_iter</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
    <span class="n">w_reg_sgd</span>      <span class="o">=</span> <span class="n">train_ridge_SGD</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">shrinkage</span><span class="p">,</span> <span class="n">final_iter</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;shrinkage  = </span><span class="si">{:.2f}</span><span class="s2"> final_iter = </span><span class="si">{:d}</span><span class="s2"> learning_rate = </span><span class="si">{:.2f}</span><span class="s2"> deg = </span><span class="si">{:d}</span><span class="s2"> threshold = </span><span class="si">{:.2e}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">shrinkage</span><span class="p">,</span> <span class="n">final_iter</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">deg</span><span class="p">,</span> <span class="n">threshold</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;w_norm_eqn = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">w_norm_eqn</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;w_reg_bgd  = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">w_reg_bgd</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;w_reg_sgd  = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">w_reg_sgd</span><span class="p">))</span></div>

<span class="c1">##=======================================================================</span>
<span class="c1">## Main Program</span>
<span class="c1">##=======================================================================</span>
<div class="viewcode-block" id="main"><a class="viewcode-back" href="../polyfit.html#polyfit.main">[docs]</a><span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Run main function.&quot;&quot;&quot;</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="s1">&#39;Univariate Exercise.&#39;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;-i&#39;</span><span class="p">,</span> <span class="s1">&#39;--input_data_dir&#39;</span><span class="p">,</span>
                        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">default</span><span class="o">=</span><span class="s1">&#39;../data/polyfit&#39;</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Directory for the polyfit dataset.&#39;</span><span class="p">)</span>
    <span class="n">FLAGS</span><span class="p">,</span> <span class="n">unparsed</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_known_args</span><span class="p">()</span>


    <span class="c1">##=======================================================================</span>
    <span class="c1">## Question 4: Polynomial Univariate Ridge Regularization</span>
    <span class="c1">##=======================================================================</span>
    <span class="n">fh_train</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">input_data_dir</span> <span class="o">+</span> <span class="s2">&quot;/train.txt&quot;</span>
    <span class="n">fh_test</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">input_data_dir</span> <span class="o">+</span> <span class="s2">&quot;/test.txt&quot;</span>
    <span class="n">fh_valid</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">input_data_dir</span> <span class="o">+</span> <span class="s2">&quot;/devel.txt&quot;</span>

    <span class="n">X</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">normalize_data</span><span class="p">(</span><span class="n">fh_train</span><span class="p">,</span><span class="n">deg</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

    <span class="c1"># qn4 a,b,c</span>
    <span class="n">plot_3data</span><span class="p">()</span>


    <span class="c1"># qn4d 1 without regularization</span>
    <span class="n">choose_learning_rate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">t</span><span class="p">)</span>
    <span class="n">plot_cost_hist_unreg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">t</span><span class="p">)</span>
    <span class="n">compare_w_unreg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">t</span><span class="p">)</span>

    <span class="c1"># qn4d 2 with regularization</span>
    <span class="n">plot_cost_hist_reg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">t</span><span class="p">)</span></div>
    <span class="c1"># compare_w_reg(X,t)</span>



<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">time</span>

    <span class="c1"># Beginning time</span>
    <span class="n">program_begin_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">begin_ctime</span>        <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">ctime</span><span class="p">()</span>

    <span class="c1">#  Run the main program</span>
    <span class="n">main</span><span class="p">()</span>


    <span class="c1"># Print the time taken</span>
    <span class="n">program_end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">end_ctime</span>        <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">ctime</span><span class="p">()</span>
    <span class="n">seconds</span>          <span class="o">=</span> <span class="n">program_end_time</span> <span class="o">-</span> <span class="n">program_begin_time</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">s</span>             <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span><span class="n">seconds</span><span class="p">,</span> <span class="mi">60</span><span class="p">)</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">m</span>             <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="mi">60</span><span class="p">)</span>
    <span class="n">d</span><span class="p">,</span> <span class="n">h</span>             <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="mi">24</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Begin time: &quot;</span><span class="p">,</span> <span class="n">begin_ctime</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;End   time: &quot;</span><span class="p">,</span> <span class="n">end_ctime</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Time taken: </span><span class="si">{0: .0f}</span><span class="s2"> days, </span><span class="si">{1: .0f}</span><span class="s2"> hours, </span><span class="se">\</span>
<span class="s2">      </span><span class="si">{2: .0f}</span><span class="s2"> minutes, </span><span class="si">{3: f}</span><span class="s2"> seconds.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">s</span><span class="p">))</span>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Bhishan&#39;s 1 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2017, Bhishan Poudel.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.5.6.
    </div>
  </body>
</html>